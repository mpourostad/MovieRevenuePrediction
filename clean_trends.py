# -*- coding: utf-8 -*-
"""CLEAN-TRENDS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nZnsE7LsMwQrTrIANxbttxty3KGEkXD2

# Dataset
"""

import pandas as pd
import numpy as np
from scipy.stats import pearsonr
cl_data = pd.read_csv("clean_data_Trends.csv")

cl_data.head()

cl_data = cl_data.iloc[: , 1:]

cl_data.head()

df = cl_data # on cleaned dataset

df.head()

# get the name of the column to be moved
column_name = 'worldwide'
# create a new dataframe with the desired column order
df = df[[col for col in df.columns if col != column_name] + [column_name]]

df.head()

df.shape

df.info()

#df = df.drop('before_premiere_trends',axis = 1)
#df = df.drop('movie_facebook_likes', axis = 1)

df.describe()

#Finding Unique Values
print(df.nunique())

"""#Univariate Analysis"""

import seaborn as sns

# Univariate Analysis
sns.distplot(df.duration, color="purple");

# Univariate Analysis
sns.distplot(df.director_facebook_likes, color="purple");

# Univariate Analysis
sns.distplot(df.actor_3_facebook_likes, color="purple");

# Univariate Analysis
sns.distplot(df.actor_2_name, color="purple");

# Univariate Analysis
sns.distplot(df.actor_1_facebook_likes, color="purple");

# Univariate Analysis
sns.distplot(df.actor_1_name, color="purple");

# Univariate Analysis
sns.displot(df.cast_total_facebook_likes, color="purple");

# Univariate Analysis
sns.distplot(df.actor_3_name, color="purple");

# Univariate Analysis
sns.distplot(df.budget_x, color="purple");

# Univariate Analysis
sns.distplot(df.actor_2_facebook_likes, color="purple");

# Univariate Analysis
#sns.distplot(df.movie_facebook_likes, color="purple")

# Univariate Analysis
sns.distplot(df.director, color="purple");

# Univariate Analysis
sns.distplot(df.writer, color="purple");

# Univariate Analysis
sns.distplot(df.producer, color="purple");

# Univariate Analysis
sns.distplot(df.composer, color="purple");

# Univariate Analysis
sns.distplot(df.cinematographer, color="purple");

# Univariate Analysis
sns.distplot(df.main_actor_4, color="purple");

# Univariate Analysis
sns.distplot(df.director, color="purple");

df.columns = df.columns.str.replace('-', '_')

sns.distplot(df.worldwide, color="purple");

"""# Transformation of feature variables"""

from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

pt = PowerTransformer(method="yeo-johnson", standardize=False)
pt.fit(df["duration"].values.reshape(-1, 1))
temp = pt.transform(df["duration"].values.reshape(-1, 1))

sns.distplot(temp, color='blue');

from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

pt = PowerTransformer(method="yeo-johnson", standardize=False)
pt.fit(df["director_facebook_likes"].values.reshape(-1, 1))
temp = pt.transform(df["director_facebook_likes"].values.reshape(-1, 1))

sns.distplot(temp, color='blue');

from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

pt = PowerTransformer(method="yeo-johnson", standardize=False)
pt.fit(df["actor_3_facebook_likes"].values.reshape(-1, 1))
temp = pt.transform(df["actor_3_facebook_likes"].values.reshape(-1, 1))

sns.distplot(temp, color='blue');

from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

pt = PowerTransformer(method="yeo-johnson", standardize=False)
pt.fit(df["actor_1_facebook_likes"].values.reshape(-1, 1))
temp = pt.transform(df["actor_1_facebook_likes"].values.reshape(-1, 1))

sns.distplot(temp, color='blue');

from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

pt = PowerTransformer(method="yeo-johnson", standardize=False)
pt.fit(df["cast_total_facebook_likes"].values.reshape(-1, 1))
temp = pt.transform(df["cast_total_facebook_likes"].values.reshape(-1, 1))

sns.distplot(temp, color='blue');

from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

pt = PowerTransformer(method="yeo-johnson", standardize=False)
pt.fit(df["budget_x"].values.reshape(-1, 1))
temp = pt.transform(df["budget_x"].values.reshape(-1, 1))

sns.distplot(temp, color='blue');

from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

pt = PowerTransformer(method="yeo-johnson", standardize=False)
pt.fit(df["actor_2_facebook_likes"].values.reshape(-1, 1))
temp = pt.transform(df["actor_2_facebook_likes"].values.reshape(-1, 1))

sns.distplot(temp, color='blue');

#from sklearn.preprocessing import PowerTransformer          
#importing Power Transformer for transformation

#pt = PowerTransformer(method="yeo-johnson", standardize=False)
#pt.fit(df["movie_facebook_likes"].values.reshape(-1, 1))
#temp = pt.transform(df["movie_facebook_likes"].values.reshape(-1, 1))

#sns.distplot(temp, color='blue');

"""# Split"""

# now let's train a_df
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

print(X[0])

print(y[0])

X.size

y.size

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)
#X_train, X_test, y_train, y_test = X.head(int(len(X)*0.7)), X.tail(int(len(X)*0.3)),y.head(int(len(y)*0.7)), y.tail(int(len(y)*0.3))

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""#LR"""

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)

corr, _ = pearsonr(y_test, y_pred)
print('Pearsons Corelation: %3f' % corr)
lr_pc = corr

from sklearn import metrics
meanAbErr = metrics.mean_absolute_error(y_test, y_pred)
meanSqErr = metrics.mean_squared_error(y_test, y_pred)
rootMeanSqErr = np.sqrt(metrics.mean_squared_error(y_test, y_pred))
#lr = regressor.metrics.r2_score(y_pred,y_test)*100
print('R squared: {:.2f}'.format(metrics.r2_score(y_pred,y_test)*100))
print('Mean Absolute Error:', meanAbErr)
print('Mean Square Error:', meanSqErr)
print('Root Mean Square Error:', rootMeanSqErr)

"""#**SVR**"""

from sklearn.svm import SVR
regressor = SVR(kernel = 'rbf')
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)

corr, _ = pearsonr(y_test, y_pred)
print('Pearsons Corelation: %3f' % corr)
svr_pc = corr

"""#**DT**"""

from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 0)
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)

corr, _ = pearsonr(y_test, y_pred)
print('Pearsons Corelation: %3f' % corr)
dt_pc = corr

"""#**RF**"""

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)

corr, _ = pearsonr(y_test, y_pred)
print('Pearsons Corelation: %3f' % corr)
rf_pc = corr

from sklearn import metrics
meanAbErr = metrics.mean_absolute_error(y_test, y_pred)
meanSqErr = metrics.mean_squared_error(y_test, y_pred)
rootMeanSqErr = np.sqrt(metrics.mean_squared_error(y_test, y_pred))
#lr = regressor.metrics.r2_score(y_pred,y_test)*100
print('R squared: {:.2f}'.format(metrics.r2_score(y_pred,y_test)*100))
print('Mean Absolute Error:', meanAbErr)
print('Mean Square Error:', meanSqErr)
print('Root Mean Square Error:', rootMeanSqErr)

"""#**ANN**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

import tensorflow as tf

ann = tf.keras.models.Sequential()

ann.add(tf.keras.layers.Dense(units=6, activation='relu'))

ann.add(tf.keras.layers.Dense(units=6, activation='relu'))

ann.add(tf.keras.layers.Dense(units=1, activation='linear'))

ann.compile(optimizer = 'adam', loss = 'mean_squared_error')

ann.fit(X_train, y_train, batch_size = 16, epochs = 100)

y_pred = ann.predict(X_test)
#y_pred = (y_pred > 0.5)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

y_test

y_pred

y_pred = y_pred.reshape(1,len(y_pred))

y_pred

mlr_diff = pd.DataFrame({'Actual value': y_test, 'Predicted value': y_pred[0]})
print(mlr_diff.corr())
a = mlr_diff.corr()

correlation_value = a.loc['Actual value', 'Predicted value']
print(correlation_value)
ann_pc = correlation_value

"""#Model Selection"""

model_names=[]
model_names.append('Linear Regr')
model_names.append('SVM')
model_names.append('Dec-Tree')
model_names.append('Ran-Forest')
model_names.append('ANN')

results = []
results.append(lr_pc)
results.append(svr_pc)
results.append(dt_pc)
results.append(rf_pc)
results.append(ann_pc)

import matplotlib.pyplot as plt

# Define custom colors for each bar
colors = ['orange', 'brown', 'cyan', 'indigo', 'purple']

# Create a bar chart of the accuracy scores for each model
plt.bar(model_names, results, color = colors)

# Add labels and title to the chart
plt.xlabel('Model')
plt.ylabel('Pearson')
plt.title('Pearson Corelation for different models')

# Adjust the y-axis limits and ticks
plt.ylim(0.55, 0.8)  # Set the desired lower and upper limits of the y-axis
plt.yticks([0.55, 0.6, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8])  # Set the desired tick positions on the y-axis

# Show the chart
plt.show()